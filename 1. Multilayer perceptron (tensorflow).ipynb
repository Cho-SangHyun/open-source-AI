{"cells":[{"cell_type":"markdown","metadata":{"id":"Kq88oxVC29cs"},"source":["# Multilayer perceptron\n","\n","간단한 신경망으로 해봅시다! \n","\n","**contents**\n","\n","1.   버전 체크\n","2.   신경망 기본 구조\n","3.   학습 및 모니터링\n","4.   과적합 Overfitting 해결\n","  \n","      4.1. 가중치 감소\n","\n","      4.2. 드랍아웃\n","\n","      4.3. 배치정규화\n","\n","---\n"]},{"cell_type":"markdown","metadata":{"id":"vOl0-LEay3sy"},"source":["# 1. 버전 체크\n","\n","현재 저는 2.8.2 버전이네요."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":2280,"status":"ok","timestamp":1663238468915,"user":{"displayName":"김동재[인공지능융합학과]","userId":"07970455560125973856"},"user_tz":-540},"id":"fxFXYstES9Pr","outputId":"b781b949-9f2f-4436-e00e-33990e2c21ba"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'2.8.2'"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import tensorflow as tf\n","tf.__version__"]},{"cell_type":"markdown","metadata":{"id":"-xjmHpFJwk1b"},"source":["# 2. Neural network\n","\n","MNIST classification 예제입니다.\n","\n","딥러닝 모델의 일반적인 구성은 다음과 같습니다.\n","\n","\n","1.   데이터 - 어떤 차원의 데이터가 들어오는지에 따라서 네트워크 구성도 달라집니다.\n","2.   신경망 구조 - Dense Layer 혹은 Conv layer 등 다른 네트워크 구조를 쓸 수가 있습니다.\n","3.   손실함수 Loss function  - 상황에 맞게 수정할 필요가 있습니다. \n","4.   최적화 방법 Optimizer - backpropagation 을 어떻게 할 지 바꿔주며 수행해 볼 수 있습니다.\n","\n","이번 notebook 에서는 간단한 neural network 를 만들어 MNIST 분류를 실제로 해봅시다.\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"RdFymYvCzDzA"},"source":["## 2.1. 데이터\n","\n","MNIST 데이터를 활용할 겁니다. 보통은 여러분 컴퓨터에 저장된 파일을 불러와서 사용하시겠지만, 여기서는 웹에서 MNIST 데이터를 직접 다운받아 활용하도록 하겠습니다.\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":739,"status":"ok","timestamp":1663238469647,"user":{"displayName":"김동재[인공지능융합학과]","userId":"07970455560125973856"},"user_tz":-540},"id":"S_iplFkuzAw8","outputId":"86598de2-c551-4440-89bc-3ed66d6bc0be"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","11501568/11490434 [==============================] - 0s 0us/step\n"]}],"source":["mnist = tf.keras.datasets.mnist\n","\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","x_train, x_test = x_train / 255.0, x_test / 255.0\n"]},{"cell_type":"markdown","metadata":{"id":"neLmH2R_8jtn"},"source":["input data x_train 은 (60000,28,28) 의 크기를 갖고 있습니다."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1663238469647,"user":{"displayName":"김동재[인공지능융합학과]","userId":"07970455560125973856"},"user_tz":-540},"id":"H8pY9WtD49M9","outputId":"72a2b79c-e772-4d37-bcbf-a8aa5308bb19"},"outputs":[{"data":{"text/plain":["(60000, 28, 28)"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["x_train.shape"]},{"cell_type":"markdown","metadata":{"id":"_U5jhwggSRSf"},"source":["그리고 이 데이터를 텐서플로우에서 제공하는 Dataset 이라는 클래스로 옮깁니다.\n","\n","우리는 60000개의 데이터를 한번에 넣지 않고 작은 batch로 뽑아서 네트워크를 학습 시킬겁니다. 그래야 효율적이니까요 (다른 중요한 이유들도 있지만 아직 다루지 않았습니다)\n","\n","데이터를 이런 batch 단위로 묶는 것, 그리고 데이터를 뒤섞어주는 (stochastic gradient descent 같은데서도 중요한 부분이겠죠) 기능까지 있어서 유용하게 활용할 수 있습니다.\n","\n","옛날엔 이게 없어서 일일히 index 지정해서 넣기도 했습니다.  "]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":3374,"status":"ok","timestamp":1663238473448,"user":{"displayName":"김동재[인공지능융합학과]","userId":"07970455560125973856"},"user_tz":-540},"id":"2ZJESJtYPLvF"},"outputs":[],"source":["train_ds = tf.data.Dataset.from_tensor_slices(\n","    (x_train, y_train)).shuffle(10000).batch(32)\n","\n","test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"]},{"cell_type":"markdown","metadata":{"id":"mbA90dmdz-if"},"source":["## 2.2. 신경망 구조\n","\n","네트워크를 어떻게 구축하시든, 그건 여러분 마음입니다. 그렇지만 적어도 class 로 구성하는 연습을 해두시면 좋아요. 그래야 나중에 네트워크를 저장하고 다시 불러오는 과정들이 어렵지 않고, 상속하여 새로운 네트워크를 만들기도 쉽습니다.\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"654lKkU59au8"},"source":["텐서플로우는 케라스 라고 하는 딥러닝 라이브러를 포함하고 있습니다.\n","\n","옛날에는 이게 별도의 라이브러리였는데, 텐서플로우로 통합됐어요.\n","\n","이 케라스를 통한 네트워크 구성방법은 세가지가 있습니다.\n","\n","\n","\n","*   Sequential 절차형 \n","*   Functional 함수형\n","*   Subclass   서브클래스 - 간단\n","\n","\n","\n","과거의 텐서플로우는 복잡하게 하나하나 input $x$ 와 hidden layer 1의 값 $h_1$, 그리고 다시 그 다음 layer 의 activity 인 $h_2$ 와 연결하는 작업이 필요했었습니다. (Tensorflow version 0.12 이하, 1.X 버전에서도 그렇게 많이들 했구요.) \n","\n","근데 요즘은 케라스에서 제공하는 간단한 함수들로 구성할 수 있도록 많이 나오고 있어요. 이런걸 활용해 보겠습니다."]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1663238473448,"user":{"displayName":"김동재[인공지능융합학과]","userId":"07970455560125973856"},"user_tz":-540},"id":"yQ0WH3Y39_tn"},"outputs":[],"source":["from tensorflow.keras.layers import Dense, Flatten, Conv2D\n","from tensorflow.keras import Model"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":310,"status":"ok","timestamp":1663238473756,"user":{"displayName":"김동재[인공지능융합학과]","userId":"07970455560125973856"},"user_tz":-540},"id":"nofccF0_zA0c"},"outputs":[],"source":["# Subclassing\n","# Keras 의 Model 을 상속받아 만듭니다. 꼭 이 형태로 해야하는건 아닌데, 이게 편해서 이렇게 많이 합니다.\n","class MLP_3L(Model):\n","  def __init__(self):\n","    # 상속\n","    # 파이썬 클래스 상속 받을 녀석의 속성 및 메서드 가져오기\n","    # 없으면 지금 DNN의 init 으로 덮어 씌워집니다. \n","    super(MLP_3L, self).__init__() \n","\n","    # Flatten \n","    # 데이터를 1차원으로 정렬합니다. (N,28,28) 이 (N,784)으로\n","    self.flatten = Flatten()\n","\n","    # Dense layers\n","    # 활성함수는 activation 을 바꿔줌으로써 바꿀 수 있습니다.\n","    self.d1 = Dense(128, activation='sigmoid')\n","    self.d2 = Dense(10, activation='sigmoid')\n","    self.d3 = Dense(10)\n","\n","    # Conv layers\n","    # Convolution neural network 에서는 Conv layer 를 쓰기도 합니다. \n","    # self.flatten = Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1))\n","    # self.d1 = MaxPooling2D((2, 2))\n","    # self.d2 = Flatten()\n","    # self.d3 = Dense(128, activation='sigmoid')\n","    # self.d4 = Dense(10)\n","\n","\n","  def call(self, inputs):\n","    # call 은 이 Keras Model 을 상속받아 사용할때 쓰는 방식입니다. x가 들어오면 그것에 대해서 네트워크 연산해서 return 줍니다.\n","    x = self.flatten(inputs)\n","    x = self.d1(x)\n","    x = self.d2(x)\n","    return self.d3(x)\n","\n","# 모델 생성\n","model = MLP_3L()\n"]},{"cell_type":"markdown","metadata":{"id":"1L4m9pxSLFSE"},"source":["## 2.3. 손실함수 와 최적화\n","\n","손실 함수 loss function 는 classification 문제에선 보통 cross entropy를 사용합니다.\n"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1663238473756,"user":{"displayName":"김동재[인공지능융합학과]","userId":"07970455560125973856"},"user_tz":-540},"id":"FLJqlQvUK3MG"},"outputs":[],"source":["# cross entropy를 사용합니다. \n","# from_logits=True 는 아웃풋이 class 에 대한 확률값이 되도록 normalize 하겠다는 의미. 모두 더해서 1이되는 확률값을 코딩하도록 만듭니다.\n","loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) "]},{"cell_type":"markdown","metadata":{"id":"6Cr_NcvGUGsJ"},"source":["\n","경사 하강법 설명할 때도 말 했지만, Global minimum 을 찾는 것은 실제로 loss function 이 어떻게 정의 되었는지 모르는 상태에선 거의 불가능에 가깝죠 ($f(x)=x^2$ 처럼 알 수 있다면 좋으련만). 그래서 여러가지 optimizer 가 개발되어왔습니다. \n","\n","여기서는 우리가 익숙한 Gradient descent의 일종인 SGD(stochastic gradient descent)를 쓸게요."]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1663238473757,"user":{"displayName":"김동재[인공지능융합학과]","userId":"07970455560125973856"},"user_tz":-540},"id":"VwynmNiLT7rr"},"outputs":[],"source":["# optimizer 사용하는 부분\n","optimizer = tf.keras.optimizers.SGD()"]},{"cell_type":"markdown","metadata":{"id":"PR9z48CRNPx_"},"source":["각각 training 과 test 의 metric (acc와 loss) 을 뽑는 메서드들을 불러와놓구요"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1663238473757,"user":{"displayName":"김동재[인공지능융합학과]","userId":"07970455560125973856"},"user_tz":-540},"id":"PPlsXaVVK3me"},"outputs":[],"source":["train_loss = tf.keras.metrics.Mean(name='train_loss')\n","train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n","\n","test_loss = tf.keras.metrics.Mean(name='test_loss')\n","test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"]},{"cell_type":"markdown","metadata":{"id":"1gbE0_eQNZn-"},"source":["training 하는 것에 대해서 메서드를 하나 만듭니다.\n","\n","그냥 interpreter 로 실행하듯 해도 되는데 (약간 암산 잘하는 것), 이렇게 해야 좀 관리가 쉽겠죠?"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1663238473757,"user":{"displayName":"김동재[인공지능융합학과]","userId":"07970455560125973856"},"user_tz":-540},"id":"DrzZahtEz-QV"},"outputs":[],"source":["def train_step(images, labels):\n","  # tf 2.x의 문법입니다. loss 를 저장하는 어떤 tape (기록장치) 이 있고 거기에 저장해놓고 backpropagation 하겠다 이런 의미입니다.\n","  with tf.GradientTape() as tape:\n","    # training=True is only needed if there are layers with different\n","    # behavior during training versus inference (e.g. Dropout).\n","    predictions = model(images, training=True)\n","    loss = loss_object(labels, predictions)\n","  gradients = tape.gradient(loss, model.trainable_variables)\n","  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","\n","  train_loss(loss)\n","  train_accuracy(labels, predictions)"]},{"cell_type":"markdown","metadata":{"id":"rXGfu5MGNkYk"},"source":["test 는 아시다시피 학습 training 과정에서 경험하지 못했던 test dataset 에 대해서 성능이 얼마나 좋은지/나쁜지를 보는 과정입니다. 과적합 overfitting 의 판단 기준이 되죠.\n"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1663238473758,"user":{"displayName":"김동재[인공지능융합학과]","userId":"07970455560125973856"},"user_tz":-540},"id":"zsZzOxA_y9yv"},"outputs":[],"source":["def test_step(images, labels):\n","  # training=False is only needed if there are layers with different\n","  # behavior during training versus inference (e.g. Dropout).\n","  predictions = model(images, training=False)\n","  t_loss = loss_object(labels, predictions)\n","\n","  test_loss(t_loss)\n","  test_accuracy(labels, predictions)"]},{"cell_type":"markdown","metadata":{"id":"a7oBXP0rKA7n"},"source":["## 2.4. 학습 시작\n","\n","드디어 네트워크 하나 돌려봅니다. \n","\n","`EPOCHS = 5` 는 에폭이 5개라는 뜻인데, 1 에폭은 주어진 데이터셋을 한번 전부 돌리는 것을 의미합니다. \n","\n","우리의 training data 가 60000,28,28 이었으니까, 한 에폭당 60000, 즉 네트워크는 데이터를 총 30만번 보게 되겠네요!"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"LaBYYPRJKA7o"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1, Loss: 2.2270901203155518, Accuracy: 27.15833282470703, Test Loss: 2.097231864929199, Test Accuracy: 37.470001220703125\n","Epoch 2, Loss: 1.9062293767929077, Accuracy: 44.56500244140625, Test Loss: 1.693687915802002, Test Accuracy: 49.349998474121094\n","Epoch 3, Loss: 1.5226867198944092, Accuracy: 57.6150016784668, Test Loss: 1.3473405838012695, Test Accuracy: 63.11000061035156\n","Epoch 4, Loss: 1.2241953611373901, Accuracy: 67.99832916259766, Test Loss: 1.0958784818649292, Test Accuracy: 71.0\n","Epoch 5, Loss: 1.0179013013839722, Accuracy: 73.90833282470703, Test Loss: 0.929245114326477, Test Accuracy: 76.12000274658203\n"]}],"source":["EPOCHS = 5\n","\n","for epoch in range(EPOCHS):\n","  # Reset the metrics at the start of the next epoch\n","  train_loss.reset_states()\n","  train_accuracy.reset_states()\n","  test_loss.reset_states()\n","  test_accuracy.reset_states()\n","\n","  for images, labels in train_ds:\n","    train_step(images, labels)\n","\n","  for test_images, test_labels in test_ds:\n","    test_step(test_images, test_labels)\n","\n","  print(\n","    f'Epoch {epoch + 1}, '\n","    f'Loss: {train_loss.result()}, '\n","    f'Accuracy: {train_accuracy.result() * 100}, '\n","    f'Test Loss: {test_loss.result()}, '\n","    f'Test Accuracy: {test_accuracy.result() * 100}'\n","  )"]},{"cell_type":"markdown","metadata":{"id":"WYYvIYay0wAv"},"source":["# 3. 학습 및 모니터링\n","\n","학습을 진행해봅시다. 우리는 학습을 진행하면서 모니터링을 할 겁니다. 이 모니터링을 통해서, 웨이트가 어떻게 변화하는지 볼거고, 그래서 나중에 어떻게 조절해야하는지 까지 확인을 할 겁니다.\n","\n","그러려면 네트워크 학습파트를 다시 정의 해야합니다. \n","**왜?** \n","\n","텐서보드라는걸 쓸거고, 그러려면 텐서보드로 데이터를 저장할 값들을 만들어 줘야 합니다.\n","\n","그리고 또, 이 값들을 실제로 *학습과정에서* 저장을 해야겠죠!\n","\n"]},{"cell_type":"markdown","metadata":{"id":"alqAgkMBPYEF"},"source":[" ## 3.1. 일단 텐서보드 불러옵시다.\n","\n","이렇게 하면 저장을 하는거에요 텐서보드에 보일 수 있게. "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"P_6sFrOQJuSB"},"outputs":[],"source":["# Load the TensorBoard notebook extension\n","%load_ext tensorboard"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"-ebqomawQZSj"},"outputs":[{"data":{"application/javascript":["\n","        (async () =\u003e {\n","            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n","            url.searchParams.set('tensorboardColab', 'true');\n","            const iframe = document.createElement('iframe');\n","            iframe.src = url;\n","            iframe.setAttribute('width', '100%');\n","            iframe.setAttribute('height', '800');\n","            iframe.setAttribute('frameborder', 0);\n","            document.body.appendChild(iframe);\n","        })();\n","    "],"text/plain":["\u003cIPython.core.display.Javascript object\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["%tensorboard --logdir logs"]},{"cell_type":"markdown","metadata":{"id":"a75QlTeuPINl"},"source":["## 3.2. 텐서보드에 저장할 수 있게 만듭시다\n","\n","**저장할 값들?** 사실 우리가 이걸 앞에서 이미 만들었습니다.\n","\n","\n","\n","\u003e각각 training 과 test 의 metric (acc와 loss) 을 뽑는 메서드들을 불러와놓구요\n","```\n","train_loss = tf.keras.metrics.Mean(name='train_loss')\n","train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n","test_loss = tf.keras.metrics.Mean(name='test_loss')\n","test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n","```"]},{"cell_type":"markdown","metadata":{"id":"YGdrRHeZP19T"},"source":["**실제로 저장할 수 있도록 준비합니다**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"HJEtzJMHP_iE"},"outputs":[],"source":["# 만약 이미 저장된 값이 있으면 지웁시다.\n","!rm -rf logs/ #logs  폴더에 저장할거에요"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"VNHwtpMAP6jO"},"outputs":[],"source":["import datetime\n","current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","train_log_dir = 'logs/gradient_tape/' + current_time + '/train'\n","test_log_dir = 'logs/gradient_tape/' + current_time + '/test'\n","\n","# writer: 이게 실제로 파일을 저장하고 써주는 부분입니다. \n","train_summary_writer = tf.summary.create_file_writer(train_log_dir) \n","test_summary_writer = tf.summary.create_file_writer(test_log_dir)"]},{"cell_type":"markdown","metadata":{"id":"XfZgjULuRpi2"},"source":["그리고 이제는 학습 부분을 손 봐야 합니다.\n","\n","원래는 뭐 텐서보드 관련 summarywriter 이런게 없었어요\n","\n","```\n","EPOCHS = 5\n","\n","for epoch in range(EPOCHS):\n","  # Reset the metrics at the start of the next epoch\n","  train_loss.reset_states()\n","  train_accuracy.reset_states()\n","  test_loss.reset_states()\n","  test_accuracy.reset_states()\n","\n","  for images, labels in train_ds:\n","    train_step(images, labels)\n","\n","  for test_images, test_labels in test_ds:\n","    test_step(test_images, test_labels)\n","\n","  print(\n","    f'Epoch {epoch + 1}, '\n","    f'Loss: {train_loss.result()}, '\n","    f'Accuracy: {train_accuracy.result() * 100}, '\n","    f'Test Loss: {test_loss.result()}, '\n","    f'Test Accuracy: {test_accuracy.result() * 100}'\n","  )\n","```"]},{"cell_type":"markdown","metadata":{"id":"oTNIgFZIR31b"},"source":["그런데 이제는 여기에다가 summary writer를 집어 넣을 겁니다. "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"dyUX8dQ5UCSd"},"outputs":[{"name":"stdout","output_type":"stream","text":["20220915-104300\n"]}],"source":["!ls logs/gradient_tape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"maCJ6ARkR1Tt"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1, Loss: 0.9484335780143738, Accuracy: 75.82583618164062, Test Loss: 0.8712339401245117, Test Accuracy: 77.75\n","Epoch 2, Loss: 0.7783169746398926, Accuracy: 80.60832977294922, Test Loss: 0.7264864444732666, Test Accuracy: 81.61000061035156\n","Epoch 3, Loss: 0.7005226612091064, Accuracy: 82.6883316040039, Test Loss: 0.6576524376869202, Test Accuracy: 83.58000183105469\n","Epoch 4, Loss: 0.6376766562461853, Accuracy: 84.33499908447266, Test Loss: 0.6008005142211914, Test Accuracy: 85.22999572753906\n","Epoch 5, Loss: 0.585861086845398, Accuracy: 85.60166931152344, Test Loss: 0.5531989932060242, Test Accuracy: 86.58000183105469\n"]}],"source":["EPOCHS = 5\n","\n","for epoch in range(EPOCHS):\n","  for images, labels in train_ds:\n","    train_step(images, labels)\n","\n","  with train_summary_writer.as_default():\n","    tf.summary.scalar('loss', train_loss.result(), step=epoch)\n","    tf.summary.scalar('accuracy', train_accuracy.result(), step=epoch)\n","\n","  for test_images, test_labels in test_ds:\n","    test_step(test_images, test_labels)\n","\n","  with test_summary_writer.as_default():\n","    tf.summary.scalar('loss', test_loss.result(), step=epoch)\n","    tf.summary.scalar('accuracy', test_accuracy.result(), step=epoch)\n","\n","\n","  print(\n","    f'Epoch {epoch + 1}, '\n","    f'Loss: {train_loss.result()}, '\n","    f'Accuracy: {train_accuracy.result() * 100}, '\n","    f'Test Loss: {test_loss.result()}, '\n","    f'Test Accuracy: {test_accuracy.result() * 100}'\n","  )\n","  # Reset metrics every epoch\n","  train_loss.reset_states()\n","  test_loss.reset_states()\n","  train_accuracy.reset_states()\n","  test_accuracy.reset_states()"]},{"cell_type":"markdown","metadata":{"id":"OrWXYDjL0wGz"},"source":["위의 코드를 실행하고 아까 열어놓은 텐서보드로 가서 확인해봅시다.\n"]},{"cell_type":"markdown","metadata":{"id":"dOAeBoj8S-Y8"},"source":["## 3.3. 더 자세히 갖고 놀기.\n","\n","우리가 이런 텐서보드로 요약된 정보만 볼 수도 있긴 한데요, 가끔은 그런게 아니라 저장해놓고 나중에 불러다가 더 training 하거나, weight 값이 직접 필요하거나, hidden layer activity 가 직접적으로 필요할 때가 있어요.\n","\n","그럴땐 어떻게 할까요?\n","\n","일단 모델 구조나 좀 봅시다"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"quVSmLAqYtki"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"mlp_3l\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten (Flatten)           multiple                  0         \n","                                                                 \n"," dense (Dense)               multiple                  100480    \n","                                                                 \n"," dense_1 (Dense)             multiple                  1290      \n","                                                                 \n"," dense_2 (Dense)             multiple                  110       \n","                                                                 \n","=================================================================\n","Total params: 101,880\n","Trainable params: 101,880\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{"id":"5qc7295TmxQe"},"source":["근데 우리가 여태 쓴건 서브클래스 API 의 케라스 모델인데 이건 이후의 예제에서 쓸 수가 \n","없습니다. 그건 간단하게 정의해서 쓰려고 만든거거든요? 여기서는 함수형 api 모델을 써서 정의하고 학습하고 하는 예제를 해보죠.\n","\n","왜 안되나요? \n","\u003esubclassing api 는 크기를 저장하지 않고 쉽게 쓰려고 만든 api 기 때문에... 우리가 당연하게도 크기를 지정해야 저장을 하잖습니까?\n","\n","물론 subclassing 처럼 class 로 만들수도 있습니다. 여기서 차이점은 크기를 지정하고 고정해서 학습한다는 점이에요."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"gH-6GCt_nErS"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"mnist_model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 784)]             0         \n","                                                                 \n"," dense_3 (Dense)             (None, 128)               100480    \n","                                                                 \n"," dense_4 (Dense)             (None, 10)                1290      \n","                                                                 \n"," dense_5 (Dense)             (None, 10)                110       \n","                                                                 \n","=================================================================\n","Total params: 101,880\n","Trainable params: 101,880\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/2\n","750/750 [==============================] - 3s 4ms/step - loss: 0.9520 - accuracy: 0.7425 - val_loss: 0.4885 - val_accuracy: 0.8692\n","Epoch 2/2\n","750/750 [==============================] - 2s 3ms/step - loss: 0.4372 - accuracy: 0.8771 - val_loss: 0.3563 - val_accuracy: 0.8990\n","313/313 - 0s - loss: 0.3557 - accuracy: 0.8971 - 434ms/epoch - 1ms/step\n","Test loss: 0.35566413402557373\n","Test accuracy: 0.8970999717712402\n"]}],"source":["inputs = tf.keras.Input(shape=(784,))\n","dense = Dense(128, activation=\"relu\")\n","x = dense(inputs)\n","hidden = Dense(10)(x)\n","outputs = Dense(10)(hidden)\n","\n","model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"mnist_model\")\n","model.summary()\n","\n","# 학습\n","(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n","\n","x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\n","x_test = x_test.reshape(10000, 784).astype(\"float32\") / 255\n","\n","model.compile(\n","    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    optimizer=tf.keras.optimizers.SGD(),\n","    metrics=[\"accuracy\"],\n",")\n","\n","history = model.fit(x_train, y_train, batch_size=64, epochs=2, validation_split=0.2)\n","\n","test_scores = model.evaluate(x_test, y_test, verbose=2)\n","print(\"Test loss:\", test_scores[0])\n","print(\"Test accuracy:\", test_scores[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"rsPmhnTtnWJ7"},"outputs":[{"data":{"image/png":"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\n","text/plain":["\u003cIPython.core.display.Image object\u003e"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["tf.keras.utils.plot_model(model, \"my_first_model.png\")"]},{"cell_type":"markdown","metadata":{"id":"1WV_QcRbTbFJ"},"source":["### 저장 및 불러오기\n","\n","여기는 지금 keras를 활용하는 예시를 보여드립니다. 다른 방법 더 어려운 방법도 있는데... 그건 찾아서 해보세요.\n"]},{"cell_type":"markdown","metadata":{"id":"SDU-O7pqXB0n"},"source":["#### 아주 간단"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"8CaEl22wTT9g"},"outputs":[],"source":["model.save('logs/modelsave')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"p3-CHQ36VicM"},"outputs":[{"name":"stdout","output_type":"stream","text":["assets\tkeras_metadata.pb  saved_model.pb  variables\n"]}],"source":["!ls logs/modelsave"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"iAuUT-yMWgPY"},"outputs":[],"source":["model=tf.keras.models.load_model('logs/modelsave')"]},{"cell_type":"markdown","metadata":{"id":"9EzPWHCYXEvk"},"source":["#### 조금 복잡\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"PvMsQDbSXJ7c"},"outputs":[],"source":["model_json = model.to_json()\n","with open(\"logs/jsonmodel.json\",\"w\") as f:\n","  f.write(model_json)"]},{"cell_type":"markdown","metadata":{"id":"NHwxCc8OXWyj"},"source":["### Weight 가져오기\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"tFoX0v26Xepj"},"outputs":[],"source":["import h5py"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"CK2NZ77PXhc2"},"outputs":[],"source":["model.save_weights(\"logs/weights\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"bYXfM_W-YWK6"},"outputs":[{"data":{"text/plain":["\u003ctensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f36c0dffa90\u003e"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["model.load_weights(\"logs/weights\")\n","# model.compile(optimizer='',loss='',metric=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"1mw4bUNYd2AU"},"outputs":[{"data":{"text/plain":["[\u003ckeras.engine.input_layer.InputLayer at 0x7f36c0fd17d0\u003e,\n"," \u003ckeras.layers.core.dense.Dense at 0x7f36c0fd4610\u003e,\n"," \u003ckeras.layers.core.dense.Dense at 0x7f36c0fca4d0\u003e,\n"," \u003ckeras.layers.core.dense.Dense at 0x7f36c0fc3a90\u003e]"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["model.layers"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"xMBGFGBXYkCl"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[-0.03102354  0.0253844   0.03585377 ...  0.00093344  0.04625168\n","   0.01857517]\n"," [ 0.00214243 -0.07051256 -0.04047816 ...  0.07055806 -0.02422447\n","  -0.01562254]\n"," [ 0.07098978 -0.02472326  0.01814716 ...  0.00533354  0.07702283\n","   0.05650414]\n"," ...\n"," [ 0.03487177  0.05695335 -0.00963511 ... -0.07839536  0.00668011\n","   0.06191491]\n"," [ 0.06497497  0.0205372   0.02894669 ...  0.04087958  0.05171899\n","   0.07548765]\n"," [-0.0106134   0.05860495  0.02781385 ...  0.07218467 -0.04765756\n","  -0.063014  ]]\n","[ 0.01560133  0.02389565  0.00421451 -0.00493954  0.01925607 -0.01051815\n","  0.01988975  0.03865892  0.00842896 -0.01755422  0.002327    0.00472078\n","  0.00555751  0.00700078  0.00075626  0.01335391  0.05058135  0.01704356\n","  0.00326373 -0.0040328   0.01484182 -0.01640788  0.01465462  0.04272395\n","  0.03328675  0.00611384 -0.03763952  0.02124497 -0.00971257 -0.00593838\n","  0.0476092   0.00791371  0.02085746 -0.00484924  0.01791726 -0.00791811\n"," -0.03646103  0.03669408  0.0107525   0.01330924  0.04930202 -0.00492235\n","  0.0147049  -0.0129626   0.00770842  0.03604733 -0.00773157  0.06250891\n"," -0.00934636  0.06191936  0.02385603 -0.0008673   0.01514813  0.03237173\n","  0.01666228  0.00318032  0.01488404  0.03752474  0.01018091  0.00851644\n","  0.0378238   0.00234844  0.07545825  0.00226212  0.05684783 -0.00434964\n","  0.00216355  0.00452371  0.0007263  -0.03762262  0.00427734 -0.00773253\n","  0.00589737  0.01417838 -0.00752644  0.03596538  0.01712756 -0.01488572\n","  0.0177974   0.00449858 -0.00504469  0.00516916  0.02622834  0.01148532\n"," -0.00696858  0.00497289 -0.00931493  0.00539508  0.00720497  0.04147551\n","  0.06472053  0.04180561  0.02113687 -0.00881294  0.01728444  0.00769431\n"," -0.00715413  0.00414344 -0.01245776  0.0084092   0.00162916 -0.00120477\n"," -0.0001052  -0.01974708 -0.00692687 -0.00235249 -0.01839437  0.03128323\n"," -0.027591   -0.0061559  -0.01239501  0.01381911  0.00813658 -0.00128245\n","  0.03152292 -0.00449112 -0.02043534  0.00924398  0.0247798   0.01385233\n","  0.0229551   0.01525364 -0.00040368  0.02753876  0.00208694 -0.0007243\n","  0.02972629  0.02526001]\n"]}],"source":["print(model.layers[1].get_weights()[0]) # Weights \n","print(model.layers[1].get_weights()[1]) # Bias"]},{"cell_type":"markdown","metadata":{"id":"bjvvc3omavl0"},"source":["#### Hidden layer activity\n","\n","좀 귀찮게도... Hidden layer 각각의 걸 추출하는 식을 만들어서 추출해야합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"7ioFVpW7pUS-"},"outputs":[],"source":["h_extractor = tf.keras.Model(inputs=model.input, outputs=model.layers[1].output)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"gxFdGWZNiygV"},"outputs":[{"data":{"text/plain":["\u003ctf.Tensor: shape=(1, 128), dtype=float32, numpy=\n","array([[0.8882901 , 1.5778987 , 1.4341819 , 0.        , 0.        ,\n","        0.        , 1.4025499 , 1.5185542 , 0.4624201 , 0.        ,\n","        0.21074158, 0.34377757, 0.1920734 , 0.        , 0.88879764,\n","        2.1959746 , 1.4562998 , 0.31291577, 2.5563393 , 0.        ,\n","        1.099066  , 0.        , 0.        , 0.99750584, 0.85278517,\n","        0.        , 0.6367853 , 2.746437  , 0.        , 0.04642073,\n","        0.        , 1.4089789 , 0.9447524 , 0.06947634, 1.151488  ,\n","        0.22125958, 0.8342876 , 0.978091  , 0.        , 0.4685971 ,\n","        0.8405887 , 0.        , 1.5993502 , 0.        , 0.0941684 ,\n","        1.6466273 , 0.        , 0.04832469, 0.29368365, 0.        ,\n","        0.7629724 , 0.01003119, 2.5103643 , 0.        , 0.54081756,\n","        1.1241224 , 1.3558011 , 0.        , 0.        , 0.        ,\n","        0.40310848, 0.        , 0.14098391, 1.4175414 , 0.        ,\n","        1.0652345 , 0.15856887, 0.        , 0.        , 1.3731018 ,\n","        0.5477635 , 0.9794841 , 0.6193705 , 1.487979  , 0.8251013 ,\n","        0.45486328, 0.95424896, 0.74340916, 0.5190922 , 0.        ,\n","        0.        , 2.5195618 , 1.5060713 , 0.        , 0.        ,\n","        1.3097471 , 0.4366287 , 0.37844965, 1.2985039 , 0.34255508,\n","        1.4422783 , 0.        , 0.586619  , 1.5420302 , 1.8188332 ,\n","        0.        , 0.69285417, 0.4494678 , 0.        , 0.320046  ,\n","        0.25824386, 1.0106474 , 0.56309813, 3.3570027 , 0.26492912,\n","        0.        , 1.439482  , 0.        , 1.4643859 , 0.        ,\n","        1.1730276 , 1.305804  , 0.59612596, 0.        , 0.        ,\n","        0.54756564, 0.        , 0.        , 1.053945  , 0.18088207,\n","        0.1044734 , 0.9160127 , 0.        , 0.20302047, 0.21526378,\n","        0.        , 0.7834346 , 2.9700398 ]], dtype=float32)\u003e"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np\n","h_extractor(np.random.uniform(0, 1, (1,784)).astype(np.float32))"]},{"cell_type":"markdown","metadata":{"id":"N-ABqRq-q7aJ"},"source":[" ## 3.4. 더 해보기!!!!\n","\n"," 시간이 없어서 넘어가는데, 우리가 수업시간에 배운 것들을 테스트 해보면 좋습니다.\n","\n"," \n","\n","*   SGD vs 다른 optimizer의 test loss를 텐서보드에서 비교해봅시다.\n","    * 이걸 SGD 가 아닌 다른 optimizer 를 쓰면 빨리 하강? 천천히?\n","* ReLu vs 다른 활성함수\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"OFhHLmJm0wJR"},"source":["# 4. 과적합 해결\n"]},{"cell_type":"markdown","metadata":{"id":"XOXRdTv9qrmV"},"source":["ReLu 는 한번씩 해보시구요, 여기서는 우리가 배운 내용중에\n","\n","\n","*   배치정규화\n","*   드랍아웃\n","\n","이렇게 두개만 적용시켜볼게요. 왜냐면 중지 early termination 은 여러분이 하면서 텐서보드 보고 감을 잡아야 되는 거고 weight decay 는 요즘엔 그렇게 자주 쓰진 않아요. 그냥 그런것도 있다 정도로 알고만 계십시다?\n","\n"]},{"cell_type":"markdown","metadata":{"id":"oKbvuL1OsEig"},"source":["일단 강제로 overfitting 모델 하나 만듭시다."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ML_mPzGes5ei"},"outputs":[],"source":["# 만약 이미 저장된 값이 있으면 지웁시다.\n","!rm -rf logs_overfit/ #logs_overfit  폴더에 저장할거에요"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"FkFsxhFjs5en"},"outputs":[],"source":["# 함수형 쓸때는 이렇게들 많이씁니다... 콜백이라고 해요 model.fit 할때 콜백해서 쓰려고 만드는 겁니다.\n","log_dir = \"logs_overfit/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"T5GG0CF-sMUM"},"outputs":[],"source":["# Load the TensorBoard notebook extension\n","%reload_ext tensorboard"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"7pFE0cB9sMUM"},"outputs":[{"data":{"application/javascript":["\n","        (async () =\u003e {\n","            const url = new URL(await google.colab.kernel.proxyPort(6007, {'cache': true}));\n","            url.searchParams.set('tensorboardColab', 'true');\n","            const iframe = document.createElement('iframe');\n","            iframe.src = url;\n","            iframe.setAttribute('width', '100%');\n","            iframe.setAttribute('height', '800');\n","            iframe.setAttribute('frameborder', 0);\n","            document.body.appendChild(iframe);\n","        })();\n","    "],"text/plain":["\u003cIPython.core.display.Javascript object\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["%tensorboard --logdir logs_overfit"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"hG2PAk0tsV5G"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"mnist_model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 784)]             0         \n","                                                                 \n"," dense_6 (Dense)             (None, 128)               100480    \n","                                                                 \n"," dense_7 (Dense)             (None, 10)                1290      \n","                                                                 \n","=================================================================\n","Total params: 101,770\n","Trainable params: 101,770\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/30\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(SGD, self).__init__(name, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["750/750 [==============================] - 3s 4ms/step - loss: 0.3109 - accuracy: 0.9032 - val_loss: 0.1562 - val_accuracy: 0.9540\n","Epoch 2/30\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1293 - accuracy: 0.9600 - val_loss: 0.1292 - val_accuracy: 0.9647\n","Epoch 3/30\n","750/750 [==============================] - 3s 3ms/step - loss: 0.0971 - accuracy: 0.9700 - val_loss: 0.1524 - val_accuracy: 0.9523\n","Epoch 4/30\n","750/750 [==============================] - 3s 3ms/step - loss: 0.0770 - accuracy: 0.9760 - val_loss: 0.1208 - val_accuracy: 0.9644\n","Epoch 5/30\n","750/750 [==============================] - 3s 3ms/step - loss: 0.0655 - accuracy: 0.9790 - val_loss: 0.1071 - val_accuracy: 0.9708\n","Epoch 6/30\n","750/750 [==============================] - 2s 3ms/step - loss: 0.0551 - accuracy: 0.9823 - val_loss: 0.1106 - val_accuracy: 0.9710\n","Epoch 7/30\n","750/750 [==============================] - 3s 3ms/step - loss: 0.0444 - accuracy: 0.9855 - val_loss: 0.1199 - val_accuracy: 0.9690\n","Epoch 8/30\n","750/750 [==============================] - 3s 3ms/step - loss: 0.0403 - accuracy: 0.9868 - val_loss: 0.1072 - val_accuracy: 0.9710\n","Epoch 9/30\n","750/750 [==============================] - 3s 3ms/step - loss: 0.0317 - accuracy: 0.9896 - val_loss: 0.1201 - val_accuracy: 0.9713\n","Epoch 10/30\n","750/750 [==============================] - 3s 3ms/step - loss: 0.0305 - accuracy: 0.9900 - val_loss: 0.1221 - val_accuracy: 0.9712\n","Epoch 11/30\n","750/750 [==============================] - 3s 3ms/step - loss: 0.0226 - accuracy: 0.9928 - val_loss: 0.1216 - val_accuracy: 0.9708\n","Epoch 12/30\n","750/750 [==============================] - 2s 3ms/step - loss: 0.0210 - accuracy: 0.9931 - val_loss: 0.1121 - val_accuracy: 0.9729\n","Epoch 13/30\n","750/750 [==============================] - 2s 3ms/step - loss: 0.0201 - accuracy: 0.9936 - val_loss: 0.1339 - val_accuracy: 0.9696\n","Epoch 14/30\n","750/750 [==============================] - 3s 3ms/step - loss: 0.0156 - accuracy: 0.9950 - val_loss: 0.1233 - val_accuracy: 0.9719\n","Epoch 15/30\n","750/750 [==============================] - 3s 3ms/step - loss: 0.0091 - accuracy: 0.9977 - val_loss: 0.1203 - val_accuracy: 0.9730\n","Epoch 16/30\n","750/750 [==============================] - 3s 3ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.1236 - val_accuracy: 0.9747\n","Epoch 17/30\n","750/750 [==============================] - 3s 3ms/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.1260 - val_accuracy: 0.9734\n","Epoch 18/30\n","750/750 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.1256 - val_accuracy: 0.9752\n","Epoch 19/30\n","750/750 [==============================] - 2s 3ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.1267 - val_accuracy: 0.9742\n","Epoch 20/30\n","750/750 [==============================] - 2s 3ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.1252 - val_accuracy: 0.9756\n","Epoch 21/30\n","750/750 [==============================] - 2s 3ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.1223 - val_accuracy: 0.9754\n","Epoch 22/30\n","750/750 [==============================] - 2s 3ms/step - loss: 9.8504e-04 - accuracy: 0.9999 - val_loss: 0.1234 - val_accuracy: 0.9753\n","Epoch 23/30\n","750/750 [==============================] - 2s 3ms/step - loss: 7.5881e-04 - accuracy: 1.0000 - val_loss: 0.1250 - val_accuracy: 0.9754\n","Epoch 24/30\n","750/750 [==============================] - 2s 3ms/step - loss: 6.3969e-04 - accuracy: 1.0000 - val_loss: 0.1239 - val_accuracy: 0.9760\n","Epoch 25/30\n","750/750 [==============================] - 2s 3ms/step - loss: 5.6747e-04 - accuracy: 1.0000 - val_loss: 0.1244 - val_accuracy: 0.9761\n","Epoch 26/30\n","750/750 [==============================] - 2s 3ms/step - loss: 5.4436e-04 - accuracy: 1.0000 - val_loss: 0.1263 - val_accuracy: 0.9760\n","Epoch 27/30\n","750/750 [==============================] - 3s 3ms/step - loss: 4.9641e-04 - accuracy: 1.0000 - val_loss: 0.1268 - val_accuracy: 0.9761\n","Epoch 28/30\n","750/750 [==============================] - 2s 3ms/step - loss: 4.7048e-04 - accuracy: 1.0000 - val_loss: 0.1262 - val_accuracy: 0.9762\n","Epoch 29/30\n","750/750 [==============================] - 2s 3ms/step - loss: 4.4532e-04 - accuracy: 1.0000 - val_loss: 0.1274 - val_accuracy: 0.9763\n","Epoch 30/30\n","750/750 [==============================] - 2s 3ms/step - loss: 4.1596e-04 - accuracy: 1.0000 - val_loss: 0.1286 - val_accuracy: 0.9763\n","313/313 - 0s - loss: 0.1139 - accuracy: 0.9780 - 395ms/epoch - 1ms/step\n","Test loss: 0.11390532553195953\n","Test accuracy: 0.9779999852180481\n"]}],"source":["inputs = tf.keras.Input(shape=(784,))\n","dense = Dense(128, activation=\"relu\")\n","x = dense(inputs)\n","outputs = Dense(10)(x)\n","\n","model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"mnist_model\")\n","model.summary()\n","\n","# 학습\n","(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n","\n","x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\n","x_test = x_test.reshape(10000, 784).astype(\"float32\") / 255\n","\n","model.compile(\n","    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    optimizer=tf.keras.optimizers.SGD(lr = 0.8),\n","    metrics=[\"accuracy\"],\n",")\n","\n","history = model.fit(x_train, y_train, batch_size=64, epochs=30, validation_split=0.2, callbacks=[tensorboard_callback])\n","\n","test_scores = model.evaluate(x_test, y_test, verbose=2)\n","print(\"Test loss:\", test_scores[0])\n","print(\"Test accuracy:\", test_scores[1])"]},{"cell_type":"markdown","metadata":{"id":"YredSBah0wLv"},"source":["## 배치정규화"]},{"cell_type":"markdown","metadata":{"id":"5Wjo50jr0wOL"},"source":["```\n","inputs = tf.keras.Input(shape=(784,))\n","dense = Dense(128, activation=\"relu\")\n","x = dense(inputs)\n","x = tf.keras.layers.BatchNormalization()(x)\n","outputs = Dense(10)(x)\n","```"]},{"cell_type":"markdown","metadata":{"id":"OOFeMSyO0wRA"},"source":["## 드랍아웃"]},{"cell_type":"markdown","metadata":{"id":"F2yNQefAt2Uk"},"source":["```\n","inputs = tf.keras.Input(shape=(784,))\n","dense = Dense(128, activation=\"relu\")\n","x = dense(inputs)\n","x = tf.keras.layers.Dropout(0.2)(x) # 20%로 버리겠다\n","outputs = Dense(10)(x)\n","```"]},{"cell_type":"markdown","metadata":{"id":"1Znapw89ugDv"},"source":["## 둘다 적용하고 동일한 방식 학습"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"WoieXbKOu4tU"},"outputs":[],"source":["# 만약 이미 저장된 값이 있으면 지웁시다.\n","!rm -rf logs_overfit_resolved/ #logs_overfit_resolved  폴더에 저장할거에요"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"xCeKpz4zu4tZ"},"outputs":[],"source":["# 함수형 쓸때는 이렇게들 많이씁니다... 콜백이라고 해요 model.fit 할때 콜백해서 쓰려고 만드는 겁니다.\n","log_dir = \"logs_overfit_resolved/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"eZ7QGshou4ta"},"outputs":[],"source":["# Load the TensorBoard notebook extension\n","%reload_ext tensorboard"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"FMQvYy-1u4ta"},"outputs":[{"data":{"application/javascript":["\n","        (async () =\u003e {\n","            const url = new URL(await google.colab.kernel.proxyPort(6008, {'cache': true}));\n","            url.searchParams.set('tensorboardColab', 'true');\n","            const iframe = document.createElement('iframe');\n","            iframe.src = url;\n","            iframe.setAttribute('width', '100%');\n","            iframe.setAttribute('height', '800');\n","            iframe.setAttribute('frameborder', 0);\n","            document.body.appendChild(iframe);\n","        })();\n","    "],"text/plain":["\u003cIPython.core.display.Javascript object\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["%tensorboard --logdir logs_overfit_resolved"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"i7L89oo3ukBg"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"mnist_model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_3 (InputLayer)        [(None, 784)]             0         \n","                                                                 \n"," dense_8 (Dense)             (None, 128)               100480    \n","                                                                 \n"," batch_normalization (BatchN  (None, 128)              512       \n"," ormalization)                                                   \n","                                                                 \n"," dropout (Dropout)           (None, 128)               0         \n","                                                                 \n"," dense_9 (Dense)             (None, 10)                1290      \n","                                                                 \n","=================================================================\n","Total params: 102,282\n","Trainable params: 102,026\n","Non-trainable params: 256\n","_________________________________________________________________\n","Epoch 1/30\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(SGD, self).__init__(name, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["750/750 [==============================] - 4s 4ms/step - loss: 0.3024 - accuracy: 0.9072 - val_loss: 0.1698 - val_accuracy: 0.9501\n","Epoch 2/30\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1818 - accuracy: 0.9441 - val_loss: 0.1538 - val_accuracy: 0.9559\n","Epoch 3/30\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1564 - accuracy: 0.9524 - val_loss: 0.1130 - val_accuracy: 0.9661\n","Epoch 4/30\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1378 - accuracy: 0.9565 - val_loss: 0.1050 - val_accuracy: 0.9684\n","Epoch 5/30\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1230 - accuracy: 0.9620 - val_loss: 0.1045 - val_accuracy: 0.9697\n","Epoch 6/30\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1146 - accuracy: 0.9632 - val_loss: 0.1011 - val_accuracy: 0.9722\n","Epoch 7/30\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1062 - accuracy: 0.9671 - val_loss: 0.0976 - val_accuracy: 0.9726\n","Epoch 8/30\n","750/750 [==============================] - 3s 4ms/step - loss: 0.0988 - accuracy: 0.9698 - val_loss: 0.1018 - val_accuracy: 0.9714\n","Epoch 9/30\n","750/750 [==============================] - 3s 4ms/step - loss: 0.0959 - accuracy: 0.9701 - val_loss: 0.1061 - val_accuracy: 0.9715\n","Epoch 10/30\n","750/750 [==============================] - 3s 4ms/step - loss: 0.0879 - accuracy: 0.9714 - val_loss: 0.0895 - val_accuracy: 0.9742\n","Epoch 11/30\n","750/750 [==============================] - 3s 4ms/step - loss: 0.0796 - accuracy: 0.9748 - val_loss: 0.0989 - val_accuracy: 0.9732\n","Epoch 12/30\n","750/750 [==============================] - 3s 4ms/step - loss: 0.0821 - accuracy: 0.9736 - val_loss: 0.1016 - val_accuracy: 0.9731\n","Epoch 13/30\n","750/750 [==============================] - 3s 4ms/step - loss: 0.0805 - accuracy: 0.9741 - val_loss: 0.0934 - val_accuracy: 0.9748\n","Epoch 14/30\n","750/750 [==============================] - 3s 4ms/step - loss: 0.0732 - accuracy: 0.9763 - val_loss: 0.0926 - val_accuracy: 0.9764\n","Epoch 15/30\n","750/750 [==============================] - 3s 4ms/step - loss: 0.0720 - accuracy: 0.9751 - val_loss: 0.1008 - val_accuracy: 0.9734\n","Epoch 16/30\n","750/750 [==============================] - 3s 4ms/step - loss: 0.0692 - accuracy: 0.9776 - val_loss: 0.1003 - val_accuracy: 0.9752\n","Epoch 17/30\n","750/750 [==============================] - 3s 4ms/step - loss: 0.0679 - accuracy: 0.9775 - val_loss: 0.0985 - val_accuracy: 0.9740\n","Epoch 18/30\n","750/750 [==============================] - 3s 4ms/step - loss: 0.0693 - accuracy: 0.9778 - val_loss: 0.1024 - val_accuracy: 0.9737\n","Epoch 19/30\n","750/750 [==============================] - 3s 4ms/step - loss: 0.0640 - accuracy: 0.9789 - val_loss: 0.1022 - val_accuracy: 0.9751\n","Epoch 20/30\n","750/750 [==============================] - 3s 4ms/step - loss: 0.0645 - accuracy: 0.9797 - val_loss: 0.0970 - val_accuracy: 0.9741\n","Epoch 21/30\n","750/750 [==============================] - 3s 4ms/step - loss: 0.0626 - accuracy: 0.9796 - val_loss: 0.0936 - val_accuracy: 0.9756\n","Epoch 22/30\n","750/750 [==============================] - 3s 4ms/step - loss: 0.0598 - accuracy: 0.9803 - val_loss: 0.0937 - val_accuracy: 0.9763\n","Epoch 23/30\n","750/750 [==============================] - 3s 4ms/step - loss: 0.0600 - accuracy: 0.9793 - val_loss: 0.1004 - val_accuracy: 0.9749\n","Epoch 24/30\n","750/750 [==============================] - 3s 4ms/step - loss: 0.0594 - accuracy: 0.9803 - val_loss: 0.0923 - val_accuracy: 0.9773\n","Epoch 25/30\n","750/750 [==============================] - 3s 4ms/step - loss: 0.0593 - accuracy: 0.9804 - val_loss: 0.1028 - val_accuracy: 0.9738\n","Epoch 26/30\n","750/750 [==============================] - 3s 4ms/step - loss: 0.0557 - accuracy: 0.9818 - val_loss: 0.1012 - val_accuracy: 0.9762\n","Epoch 27/30\n","750/750 [==============================] - 3s 4ms/step - loss: 0.0548 - accuracy: 0.9811 - val_loss: 0.0979 - val_accuracy: 0.9768\n","Epoch 28/30\n","750/750 [==============================] - 3s 4ms/step - loss: 0.0535 - accuracy: 0.9823 - val_loss: 0.1049 - val_accuracy: 0.9748\n","Epoch 29/30\n","750/750 [==============================] - 3s 4ms/step - loss: 0.0540 - accuracy: 0.9821 - val_loss: 0.1071 - val_accuracy: 0.9739\n","Epoch 30/30\n","750/750 [==============================] - 3s 4ms/step - loss: 0.0517 - accuracy: 0.9829 - val_loss: 0.0981 - val_accuracy: 0.9769\n","313/313 - 0s - loss: 0.0885 - accuracy: 0.9781 - 415ms/epoch - 1ms/step\n","Test loss: 0.08851379156112671\n","Test accuracy: 0.9781000018119812\n"]}],"source":["inputs = tf.keras.Input(shape=(784,))\n","dense = Dense(128, activation=\"relu\")\n","x = dense(inputs)\n","x = tf.keras.layers.BatchNormalization()(x)\n","x = tf.keras.layers.Dropout(0.2)(x)\n","outputs = Dense(10)(x)\n","\n","model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"mnist_model\")\n","model.summary()\n","\n","# 학습\n","(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n","\n","x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\n","x_test = x_test.reshape(10000, 784).astype(\"float32\") / 255\n","\n","model.compile(\n","    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    optimizer=tf.keras.optimizers.SGD(lr = 0.8),\n","    metrics=[\"accuracy\"],\n",")\n","\n","history = model.fit(x_train, y_train, batch_size=64, epochs=30, validation_split=0.2, callbacks=[tensorboard_callback])\n","\n","test_scores = model.evaluate(x_test, y_test, verbose=2)\n","print(\"Test loss:\", test_scores[0])\n","print(\"Test accuracy:\", test_scores[1])"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMren3qq+E8eDGn8fsq5Q1I","collapsed_sections":["alqAgkMBPYEF"],"name":"","toc_visible":true,"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}